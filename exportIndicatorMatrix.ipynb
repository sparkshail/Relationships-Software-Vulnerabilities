{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879969e2",
   "metadata": {
    "id": "879969e2"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4178bfc2",
   "metadata": {
    "id": "4178bfc2",
    "outputId": "b1632838-14f0-4f0d-b6a0-a51be591648a"
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from numpy import asarray\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20a0c4",
   "metadata": {
    "id": "ac20a0c4"
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998ab60f",
   "metadata": {
    "id": "998ab60f"
   },
   "outputs": [],
   "source": [
    "# reads in the CVE data sets and returns vulnerability information  \n",
    "\n",
    "def read_files(files):\n",
    "    all_entries = {0: {'CVE': \"\", 'Date': \"\",'Description': [], 'Description-Tokenized' : [],\n",
    "                   'Month-String':\"\",'Month-Int': 0,\"Year\":\"\",\"Year-Int\":0,\"Cluster\": 0,\n",
    "                    \"Time Start\": 0, \"Time End\": 0}}\n",
    "    \n",
    "    untokenized_text = list()\n",
    "    start_index = 0\n",
    "    year_num = 1\n",
    "    \n",
    "    for file in files:\n",
    "        vulns = parse_data(file)\n",
    "        for text in vulns[1]:\n",
    "            untokenized_text.append(text)\n",
    "        cur_entries = store_entries(vulns,start_index,year_num,len(files))\n",
    "        start_index = len(cur_entries) + start_index\n",
    "        all_entries = all_entries | cur_entries\n",
    "        year_num = year_num + 1\n",
    "        \n",
    "    return [all_entries,untokenized_text] \n",
    "        \n",
    "# helper method used to identify \"REJECT\" entries \n",
    "\n",
    "def is_member(target, possible):\n",
    "    for item in possible:\n",
    "        if target is item or target == item:\n",
    "              return True\n",
    "    return False\n",
    "\n",
    "# parse CVE dataset in a hierarchical format\n",
    "\n",
    "def parse_data(file):\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    notes = list()\n",
    "    cve = list()\n",
    "    pub = list()\n",
    "    for i in range(5,len(root)):\n",
    "        try:\n",
    "            #print(i)\n",
    "            token = word_tokenize(root[i][1][0].text)\n",
    "            if is_member(\"REJECT\",token) == False:  \n",
    "                pub.append(root[i][1][1].text)\n",
    "                cve.append(root[i][2].text)\n",
    "                notes.append(root[i][1][0].text)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    vulns_info = [cve,notes,pub]\n",
    "    return vulns_info\n",
    "            \n",
    "# methods for tokenizing     \n",
    "    \n",
    "def tokenize(text):\n",
    "    tokenized = list()\n",
    "    for i in range(0, len(text)):\n",
    "        filtered = remove_stopwords(word_tokenize(text[i]))\n",
    "        tokenized.append(filtered)\n",
    "                         \n",
    "    return tokenized\n",
    "\n",
    "def tokenize_single(sentence):\n",
    "    filtered = remove_stopwords(word_tokenize(sentence))\n",
    "    tokenized = [word.lower() for word in filtered] \n",
    "    return tokenized\n",
    "\n",
    "# method to remove stopwords and punctuation\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.append(')')\n",
    "    stop_words.append('(')\n",
    "    stop_words.append('.')\n",
    "    stop_words.append('')\n",
    "    filtered_sentence = [w for w in text if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    " \n",
    "    for w in text:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "# read vulnerability text for doc2vec model training \n",
    "\n",
    "def read_corpus(text, tokens_only=False):\n",
    "    count=0\n",
    "    for doc in text:\n",
    "        count+=1\n",
    "        tokens = gensim.utils.simple_preprocess(doc)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [count])\n",
    "\n",
    "            \n",
    "# build and train a doc2vec model on all vulnerability text          \n",
    "            \n",
    "def build_doc2vec(untokenized_text):\n",
    "    train_corpus = list(read_corpus(untokenized_text))\n",
    "    test_corpus = list(read_corpus(untokenized_text, tokens_only=True))\n",
    "    model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=20)\n",
    "    model.build_vocab(train_corpus)\n",
    "    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# converts the vulnerability text to vectors. text is a list of tokenized sentences for the entire data set\n",
    "# model is a doc2vec model \n",
    " \n",
    "def compute_vectors(text,model):\n",
    "    vectors = list()\n",
    "    for sentence in text:\n",
    "        vectors.append(model.infer_vector(sentence))\n",
    "    return vectors\n",
    "        \n",
    "    \n",
    "# store information of each vulnerability entry in a dictionary. Includes CVE ID, Publication date, vulnerability\n",
    "# description, tokenized description, month as a string, and month as an int (1-12)\n",
    "    \n",
    "def store_entries(vulns,start_index,year_num,total_years):\n",
    "    # Create dictionaries for every year \n",
    "    entries = {start_index: {'CVE': \"\", 'Date': \"\",'Description': [], 'Description-Tokenized' : [],\n",
    "                   'Month-String':\"\",'Month-Int': 0,\"Year\":\"\",\"Year-Int\":0,\"Time Start\": 0, \"Time End\": 0}}\n",
    "    j=0\n",
    "\n",
    "    for i in range(start_index,start_index+len(vulns[0])):\n",
    "        entries[i] = {}\n",
    "        entries[i]['CVE'] = vulns[0][j]\n",
    "        entries[i]['Date'] = vulns[2][j]\n",
    "        entries[i]['Description'] = vulns[1][j]\n",
    "        tokenized = tokenize_single(vulns[1][j])\n",
    "        desc_tokenized = remove_stopwords(tokenized)\n",
    "        entries[i]['Description-Tokenized'] = desc_tokenized\n",
    "        entries[i]['Month-String'] = \"n/a\"\n",
    "        entries[i]['Month-Int'] = 0\n",
    "        entries[i][\"Year\"] = entries[i]['Date'][0:4]\n",
    "        entries[i][\"Year-Int\"] = year_num\n",
    "        j = j + 1\n",
    "\n",
    "    for i in range(start_index,start_index+len(vulns[0])):\n",
    "        if str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '1':\n",
    "            entries[i][\"Month-String\"] = \"January\"\n",
    "            entries[i][\"Month-Int\"] = 1\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '2':\n",
    "            entries[i][\"Month-String\"] = \"February\"\n",
    "            entries[i][\"Month-Int\"] = 2\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '3':\n",
    "            entries[i][\"Month-String\"] = \"March\"\n",
    "            entries[i][\"Month-Int\"] = 3\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '4':\n",
    "            entries[i][\"Month-String\"] = \"April\"\n",
    "            entries[i][\"Month-Int\"] = 4\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '5':\n",
    "            entries[i][\"Month-String\"] = \"May\"\n",
    "            entries[i][\"Month-Int\"] = 5\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '6':\n",
    "            entries[i][\"Month-String\"] = \"June\"\n",
    "            entries[i][\"Month-Int\"] = 6\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '7':\n",
    "            entries[i][\"Month-String\"] = \"July\"\n",
    "            entries[i][\"Month-Int\"] = 7\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '8':\n",
    "            entries[i][\"Month-String\"] = \"August\"\n",
    "            entries[i][\"Month-Int\"] = 8\n",
    "        elif str(entries[i]['Date'])[5] == '0' and entries[i]['Date'][6] == '9':\n",
    "            entries[i][\"Month-String\"] = \"September\"\n",
    "            entries[i][\"Month-Int\"] = 9\n",
    "        elif str(entries[i]['Date'])[5] == '1' and entries[i]['Date'][6] == '0':\n",
    "            entries[i][\"Month-String\"] = \"October\"\n",
    "            entries[i][\"Month-Int\"] = 10\n",
    "        elif str(entries[i]['Date'])[5] == '1' and entries[i]['Date'][6] == '1':\n",
    "            entries[i][\"Month-String\"] = \"November\"\n",
    "            entries[i][\"Month-Int\"] = 11\n",
    "        else:\n",
    "            entries[i][\"Month-String\"] = \"December\"\n",
    "            entries[i][\"Month-Int\"] = 12\n",
    "        \n",
    "        # get time interval \n",
    "        entries[i][\"Time Start\"] = ((year_num-1) * 12) + entries[i][\"Month-Int\"]\n",
    "        entries[i][\"Time End\"] = total_years * 12\n",
    "        \n",
    "    return entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49bb24d",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d69d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creates an inverse cosine matrix \n",
    "\n",
    "def create_cos_matrix(vectors):\n",
    "    length = len(vectors)\n",
    "    matrix = np.zeros((length, length))\n",
    "    row_means =list() \n",
    "    for i in range(0,length):\n",
    "        for j in range(i,length):\n",
    "            mean = 0\n",
    "            dist = spatial.distance.cosine(vectors[i], vectors[j])\n",
    "            cos = abs(1/(1-dist))\n",
    "            \n",
    "            #cos = abs(1/(1-spatial.distance.cosine(vectors[i], vectors[j])))\n",
    "            matrix[i][j] = cos\n",
    "            matrix[j][i] = cos \n",
    "            mean +=cos\n",
    "        \n",
    "            if(cos == 1):\n",
    "                matrix[i][j] = 999\n",
    "                matrix[j][i] = 999\n",
    "        mean = mean/length\n",
    "        row_means.append(mean)\n",
    "        \n",
    "    for i in range(0,length):\n",
    "        for j in range(i,length):\n",
    "            if  matrix[i][j] < row_means[i]:\n",
    "                matrix[i][j] = 0\n",
    "                matrix[j][i] = 0 \n",
    "                \n",
    "    return matrix\n",
    "\n",
    "def create_cos_matrix_pure(vectors):\n",
    "    length = len(vectors)\n",
    "    matrix = np.zeros((length, length))\n",
    " \n",
    "    for i in range(0,length):\n",
    "        for j in range(i,length):\n",
    "            mean = 0\n",
    "            dist = spatial.distance.cosine(vectors[i], vectors[j])\n",
    "            cos = abs(1/(1-dist))\n",
    "            #cos = abs(1/(1-spatial.distance.cosine(vectors[i], vectors[j])))\n",
    "            matrix[i][j] = cos\n",
    "            matrix[j][i] = cos \n",
    "                 \n",
    "    return matrix\n",
    "\n",
    "def create_cos_matrix_combined(vectors):\n",
    "    length = len(vectors)\n",
    "    pure_matrix = np.zeros((length, length))\n",
    "    modified_matrix = np.zeros((length, length))\n",
    "    row_means =list() \n",
    "    \n",
    "    for i in range(0,length):\n",
    "        for j in range(i,length):\n",
    "            mean = 0\n",
    "            dist = spatial.distance.cosine(vectors[i], vectors[j])\n",
    "            cos = abs(1/(1-dist))\n",
    "            modified_matrix[i][j] = cos\n",
    "            modified_matrix[j][i] = cos \n",
    "            pure_matrix[i][j] = cos\n",
    "            pure_matrix[j][i] = cos \n",
    "            mean += cos\n",
    "        \n",
    "            if(cos == 1):\n",
    "                modified_matrix[i][j] = 999\n",
    "                modified_matrix[j][i] = 999\n",
    "        mean = mean/length\n",
    "        row_means.append(mean)\n",
    "        \n",
    "    for i in range(0,length):\n",
    "        for j in range(i,length):\n",
    "            if  modified_matrix[i][j] < row_means[i]:\n",
    "                modified_matrix[i][j] = 0\n",
    "                modified_matrix[j][i] = 0 \n",
    "                \n",
    "    return [pure_matrix, modified_matrix]\n",
    "    \n",
    "    \n",
    "\n",
    "# create a spanning tree from a cosine matrix for exporting to r\n",
    "\n",
    "def get_spanning_tree(cos_matrix):\n",
    "    X = sparse.csr_matrix(cos_matrix)\n",
    "    Tcsr = minimum_spanning_tree(X)\n",
    "    arr = Tcsr.toarray().astype(float)        \n",
    "    return arr\n",
    "                \n",
    "# create a networkx graph from a cosine matrix \n",
    "    \n",
    "def create_network(cos_matrix):\n",
    "    X = sparse.csr_matrix(cos_matrix)\n",
    "    Tcsr = minimum_spanning_tree(X)\n",
    "    arr = Tcsr.toarray().astype(float)\n",
    "    G = nx.from_numpy_array(arr, parallel_edges=False, create_using=None)\n",
    "    return G\n",
    "\n",
    "    \n",
    "# convert networkx network to an igraph\n",
    "\n",
    "def create_igraph(G, entries,subnetwork = False):\n",
    "    # convert to igraph\n",
    "    h = ig.Graph.from_networkx(G)\n",
    "    weights_i = h.es[\"weight\"]\n",
    "    \n",
    "    if subnetwork == True:\n",
    "        return h\n",
    "    \n",
    "    spanning_tree = h.spanning_tree(weights=weights_i, return_tree=True)\n",
    "    start_times = list()\n",
    "    end_times = list()\n",
    "    for i in range(0,len(entries)):\n",
    "        start_times.append(entries[i]['Time Start'])\n",
    "        end_times.append(entries[i]['Time End'])\n",
    "        \n",
    "    spanning_tree.vs[\"start_time\"] = start_times\n",
    "    spanning_tree.vs[\"end_time\"] = end_times\n",
    "    \n",
    "    edge_times = list()\n",
    "    for edge in spanning_tree.es:\n",
    "        target_vertex_id = edge.target\n",
    "        edge_times.append(entries[target_vertex_id]['Time Start'])\n",
    "    \n",
    "    spanning_tree.es[\"start_time\"] = edge_times\n",
    "    spanning_tree.es[\"end_time\"] = end_times\n",
    "\n",
    "    return spanning_tree\n",
    "    \n",
    "    \n",
    "# write edge attributes to a csv file \n",
    "\n",
    "def edge_list_to_csv(I,filename):\n",
    "    row_list = [[\"start_time\",\"end_time\",\"source\",\"target\",'weight']]\n",
    "    \n",
    "    for edge in I.es:\n",
    "        source = edge.source\n",
    "        target = edge.target\n",
    "        cur = [edge['start_time'],edge['end_time'],source,target,edge['weight']]\n",
    "        row_list.append(cur)\n",
    "        \n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(row_list)\n",
    "        \n",
    "# write edge attributes to a csv file \n",
    "\n",
    "def node_list_to_csv(I,filename):\n",
    "    row_list = [[\"id\",\"start_time\",\"end_time\"]]\n",
    "    for node in I.vs:\n",
    "        row_list.append([node['_nx_name'],node['start_time'],node['end_time']])\n",
    "        \n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(row_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c349eab",
   "metadata": {},
   "source": [
    "# Indicator Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4eef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vuln_types = {'Buffer Overflow': ['overflow'], 'Buffer Underflow': ['underflow'], 'Injection': ['injection'], \n",
    "              'Broken authentication': ['authentication'], \n",
    "              'XSS': ['XSS','scripting'], 'SSRF': ['server'], 'CSRF': ['cross'], 'Null Pointer Dereference': ['pointer'],\n",
    "              'Out of Bounds': ['bounds'], 'Directory/path Traversal': ['path','directory','traversal'], \n",
    "              'Sensitive Data Exposure': ['sensitive'], 'Elevation Priveleges': ['elevation'], \n",
    "              'Spoofing': ['spoofing','spoof'], 'Denial of Service': ['denial','service'], \n",
    "              'Bypass Restrictions': ['bypass'], 'Broken Access Control': ['access'],\n",
    "              'Unauthorized Access': ['privileged'],'FTP Issues': ['FTP'],'XML External Entities':['external'],\n",
    "              'Integer Overflow':['integer'], 'SSRF':['server'],'Improper Initialization':['initialization'],\n",
    "              'Improper Sanitaization':['sanitization'],'Improper Neutralization':['neutralization'],\n",
    "             'SSL Isssues':['SSL','sockets'],'Heap Overflow':['heap']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc2ec07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vuln_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a319d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split vulnerability texts by month from each year\n",
    "\n",
    "def split_by_month(entries,num_years):\n",
    "    split = []\n",
    "    for i in range(0,num_years*12):\n",
    "        split.append([])\n",
    "    \n",
    "    for i in range(0,len(entries)):\n",
    "        month = entries[i]['Time Start']\n",
    "        split[month-1].append(entries[i]['Description-Tokenized'])\n",
    "        \n",
    "    return split\n",
    "\n",
    "def split_by_year(entries,file_length):\n",
    "    split = []\n",
    "    for i in range(0,len(files)):\n",
    "        split.append([])\n",
    "    \n",
    "    for i in range(0,len(entries)):\n",
    "        year = entries[i][\"Year-Int\"]\n",
    "        split[year-1].append(entries[i]['Description-Tokenized'])\n",
    "        \n",
    "    return split\n",
    "\n",
    "\n",
    "# get column per year of vulnerability presence (0 if present, 1 if not)\n",
    "\n",
    "def get_col(month): \n",
    "    col = []\n",
    "    for i in range(0,len(vuln_types)):\n",
    "        col.append(0)\n",
    "    \n",
    "    row = 0\n",
    "    for vuln in month:\n",
    "        for word in vuln:\n",
    "            for key,value in vuln_types.items():\n",
    "                if is_member(word,value):\n",
    "                    col[row] = 1\n",
    "                row+=1\n",
    "            row = 0\n",
    "    return col\n",
    "\n",
    "\n",
    "def create_indicator_matrix(entries,num_years):\n",
    "    months = split_by_month(entries,num_years)\n",
    "    indic_matrix = np.zeros((len(vuln_types), num_years*12))\n",
    "    col = 0\n",
    "    \n",
    "    for month in months:\n",
    "        for i in range(0,len(vuln_types)):\n",
    "            indic_matrix[i][col] = get_col(month)[i]\n",
    "        col += 1\n",
    " \n",
    "    return indic_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3f5c6",
   "metadata": {},
   "source": [
    "# Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5838a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['/CVEDatasSets/allitems-cvrf-year-1999.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2000.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2001.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2002.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2003.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2004.xml',\n",
    "         '/CVEDatasSets/allitems-cvrf-year-2005.xml',\n",
    "         '/CVEDatasSets/allitems-cvrf-year-2006.xml',\n",
    "         '/CVEDatasSets/allitems-cvrf-year-2007.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2008.xml',\n",
    "         '/CVEDatasSets/allitems-cvrf-year-2009.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2010.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2011.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2012.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2013.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2014.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2015.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2016.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2017.xml',\n",
    "         '/CVEDatasSets/allitems-cvrf-year-2018.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2019.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2020.xml',\n",
    "        '/CVEDatasSets/allitems-cvrf-year-2021.xml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d4288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(files):\n",
    "    num_years = len(files)\n",
    "    file_info = read_files(files)\n",
    "    entries = file_info[0]\n",
    "    text = file_info[1]\n",
    "    indic_matrix = create_indicator_matrix(entries,num_years)\n",
    "    return indic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae57ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_matrix = main(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e629f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = []\n",
    "for k,v in vuln_types.items():\n",
    "    row_names.append(k)\n",
    "\n",
    "# adjust years according to given data set \n",
    "months = ['Jan','Feb','Mar','April','May','June','July','Aug','Sept','Oct','Nov','Dec']\n",
    "years = ['1999','2000','2001','2002','2003','2004','2005','2006','2007','2008','2009',\n",
    "        '2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021']\n",
    "\n",
    "col_names = []\n",
    "month = 0\n",
    "year = 0\n",
    "for i in range(0,len(years)*12):\n",
    "    cur_col = \"{month} {year}\".format(month = months[month],year = years[year])\n",
    "    col_names.append(cur_col)\n",
    "    if(month==11):\n",
    "        month = 0\n",
    "        year = year+1\n",
    "    else:\n",
    "        month= month+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4417190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(indic_matrix, columns=col_names, index=row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4a9a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan 1999</th>\n",
       "      <th>Feb 1999</th>\n",
       "      <th>Mar 1999</th>\n",
       "      <th>April 1999</th>\n",
       "      <th>May 1999</th>\n",
       "      <th>June 1999</th>\n",
       "      <th>July 1999</th>\n",
       "      <th>Aug 1999</th>\n",
       "      <th>Sept 1999</th>\n",
       "      <th>Oct 1999</th>\n",
       "      <th>...</th>\n",
       "      <th>Mar 2021</th>\n",
       "      <th>April 2021</th>\n",
       "      <th>May 2021</th>\n",
       "      <th>June 2021</th>\n",
       "      <th>July 2021</th>\n",
       "      <th>Aug 2021</th>\n",
       "      <th>Sept 2021</th>\n",
       "      <th>Oct 2021</th>\n",
       "      <th>Nov 2021</th>\n",
       "      <th>Dec 2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Improper Initialization</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Improper Sanitaization</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Improper Neutralization</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSL Isssues</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heap Overflow</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Jan 1999  Feb 1999  Mar 1999  April 1999  May 1999  \\\n",
       "Improper Initialization       0.0       0.0       0.0         0.0       0.0   \n",
       "Improper Sanitaization        0.0       0.0       0.0         0.0       0.0   \n",
       "Improper Neutralization       0.0       0.0       0.0         0.0       0.0   \n",
       "SSL Isssues                   0.0       0.0       0.0         0.0       0.0   \n",
       "Heap Overflow                 0.0       0.0       0.0         0.0       0.0   \n",
       "\n",
       "                         June 1999  July 1999  Aug 1999  Sept 1999  Oct 1999  \\\n",
       "Improper Initialization        0.0        0.0       0.0        1.0       0.0   \n",
       "Improper Sanitaization         0.0        0.0       0.0        0.0       0.0   \n",
       "Improper Neutralization        0.0        0.0       0.0        0.0       0.0   \n",
       "SSL Isssues                    0.0        0.0       0.0        0.0       0.0   \n",
       "Heap Overflow                  0.0        0.0       0.0        0.0       0.0   \n",
       "\n",
       "                         ...  Mar 2021  April 2021  May 2021  June 2021  \\\n",
       "Improper Initialization  ...       1.0         1.0       1.0        1.0   \n",
       "Improper Sanitaization   ...       1.0         1.0       1.0        1.0   \n",
       "Improper Neutralization  ...       1.0         1.0       1.0        1.0   \n",
       "SSL Isssues              ...       0.0         1.0       1.0        0.0   \n",
       "Heap Overflow            ...       1.0         1.0       1.0        1.0   \n",
       "\n",
       "                         July 2021  Aug 2021  Sept 2021  Oct 2021  Nov 2021  \\\n",
       "Improper Initialization        1.0       1.0        1.0       1.0       1.0   \n",
       "Improper Sanitaization         1.0       1.0        1.0       1.0       1.0   \n",
       "Improper Neutralization        1.0       1.0        1.0       1.0       1.0   \n",
       "SSL Isssues                    0.0       0.0        0.0       1.0       0.0   \n",
       "Heap Overflow                  1.0       1.0        1.0       1.0       1.0   \n",
       "\n",
       "                         Dec 2021  \n",
       "Improper Initialization       1.0  \n",
       "Improper Sanitaization        1.0  \n",
       "Improper Neutralization       1.0  \n",
       "SSL Isssues                   0.0  \n",
       "Heap Overflow                 1.0  \n",
       "\n",
       "[5 rows x 276 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "237a37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('1999-2021indicator_matrix.csv', indic_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a31806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('1999-2021indicator_dataframe.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e26db892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  Buffer Overflow\n",
      "2 :  Buffer Underflow\n",
      "3 :  Injection\n",
      "4 :  Broken authentication\n",
      "5 :  XSS\n",
      "6 :  SSRF\n",
      "7 :  CSRF\n",
      "8 :  Null Pointer Dereference\n",
      "9 :  Out of Bounds\n",
      "10 :  Directory/path Traversal\n",
      "11 :  Sensitive Data Exposure\n",
      "12 :  Elevation Priveleges\n",
      "13 :  Spoofing\n",
      "14 :  Denial of Service\n",
      "15 :  Bypass Restrictions\n",
      "16 :  Broken Access Control\n",
      "17 :  Unauthorized Access\n",
      "18 :  FTP Issues\n",
      "19 :  XML External Entities\n",
      "20 :  Integer Overflow\n",
      "21 :  Improper Initialization\n",
      "22 :  Improper Sanitaization\n",
      "23 :  Improper Neutralization\n",
      "24 :  SSL Isssues\n",
      "25 :  Heap Overflow\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for key,value in vuln_types.items():\n",
    "    print(count,\": \",key)\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecce48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
